{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3 b. Traducción Automática de Texto\n",
    "\n",
    "Este ejercicio tiene como objetivo entrenar un modelo para traducción automática de texto (neural machine translation) del inglés a español. Para ello, haremos uso de redes recurrentes y word embeddings. \n",
    "\n",
    "![neural machine translation](img/nmt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enunciado\n",
    "\n",
    "La traducción de texto se suele realizar con modelos de tipo sequence-to-sequence, donde existe un *encoder* que codifica el lenguaje de entrada, y un *decoder* que genera el texto en el lenguaje de salida. Actualmente esto se realiza empleando redes con auto-atención (transformers), pero para este ejercicio vamos a implementar una red recurrente clásica. \n",
    "\n",
    "La implementación del modelo recurrente la puedes realizar basándote en los ejemplos:\n",
    "1. [Modelo sequence-to-sequence a nivel de caracteres con LSTM](https://keras.io/examples/nlp/lstm_seq2seq/): Este ejemplo de Keras muestra cómo entrenar un modelo seq-to-seq implementado con LSTMs para la traducción de inglés a francés. Está basado en esta antigua entrada del [blog de Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html), donde también se dan las pistas para trabajar a nivel de palabras.\n",
    "2. [Traducción de inglés a español con un transformer](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/): Este ejemplo de Keras muestra como implementar un modelo seq-to-seq de tipo transformer en Keras, y cómo procesar el dataset de traducción de inglés al español con la capa `TextVectorization`.\n",
    "3. [Traducción automática neuronal usando un modelo seq2seq a nivel de palabra](https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7): Este proyecto, cuyo código está disponible en este [repositorio de github](https://github.com/devm2024/nmt_keras), trabaja con un modelo seq-to-seq usando como tokens las palabras de las frases, para la traducción del inglés al francés. Incluye una capa de embedding vacía.\n",
    "\n",
    "Tu trabajo consistirá en adaptar el código de los ejemplos anteriores para entrenar un modelo seq-to-seq basado en LSTMs para la traducción del inglés a español. Puedes tokenizar el texto con `Tokenizer` así como con `TextVectorization`, según te convenga mejor para construir las entradas. Sin embargo, debes utilizar una capa de word embedding pre-entrenada para inglés (Glove, Word2Vec...), como vimos en las prácticas. Es suficiente con entrenar tan solo un modelo de estas características.\n",
    "\n",
    "*De forma opcional*, se valorará la comparativa del modelo obtenido con un modelo pre-entrenado de HuggingFace para la traducción de inglés al español con el dataset descargado. También se dará un punto extra se si usan métricas BLEU y ROUGE para comparar el rendimiento de los modelos.\n",
    "\n",
    "**IMPORTANTE**: Se permiten cambios en el código para adaptarlo a la GPU empleada. Es posible que el modelo no se pueda cargar al completo en la GPU, por lo que se puede simplificar (usar un subconjunto más pequeño, un tamaño de batch más pequeño, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrega\n",
    "\n",
    "La entrega de este ejercicio se realiza a través de la tarea creada para tal efecto en Enseñanza Virtual. Tienes que entregar un notebook, y el HTML generado a partir de él, cuyas celdas estén ya evaluadas.\n",
    "\n",
    "La estructura del notebook debe contener los siguientes apartados:\n",
    "\n",
    "0. Cabecera: nombre y apellidos.\n",
    "1. Dataset: descripción, carga y procesado.\n",
    "2. Selección y carga del word embedding para el inglés.\n",
    "3. Modelo y configuración creadas en Keras y su entrenamiento. Debe incluir una explicación razonada de los componentes, y de la selección de valores como el número de unidades en las redes recurrentes (LSTM/GRU), dimensión del embedding, etc.\n",
    "5. Análisis de resultados con comparativa respecto del trabajo original ([ejemplo 2](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/)) basado en transformers (*no es necesario mejorarlo*). Si se hace la parte opcional (comparar con un modelo pre-entrenado de HuggingFace), indicar la comparativa. El análisis puede ser cualitativo, haciendo pruebas de texto. *Se evaluará con 1 punto extra si se hace un análisis con métricas como BLEU y ROUGE (se pueden usar desde KerasNLP).*\n",
    "6. Bibliografía utilizada (enlaces web, material de clase, libros, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Nota importante\n",
    "-----\n",
    "**HONESTIDAD ACADÉMICA Y COPIAS: un trabajo práctico es un examen, por lo que\n",
    "debe realizarse de manera individual. La discusión y el intercambio de\n",
    "información de carácter general con los compañeros se permite (e incluso se\n",
    "recomienda), pero NO AL NIVEL DE CÓDIGO. Igualmente el remitir código de\n",
    "terceros, OBTENIDO A TRAVÉS DE LA RED o cualquier otro medio, se considerará\n",
    "plagio.** \n",
    "\n",
    "**Cualquier plagio o compartición de código que se detecte significará\n",
    "automáticamente la calificación de CERO EN LA ASIGNATURA para TODOS los\n",
    "alumnos involucrados. Por tanto a estos alumnos NO se les conservará, para\n",
    "futuras convocatorias, ninguna nota que hubiesen obtenido hasta el momento.\n",
    "SIN PERJUICIO DE OTRAS MEDIDAS DE CARÁCTER DISCIPLINARIO QUE SE PUDIERAN\n",
    "TOMAR.**\n",
    "\n",
    "-----\n",
    "\n",
    "## 3. Código para iniciarse\n",
    "\n",
    "En el [ejemplo 2](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/) indicado anteriormente, se puede ver cómo descargar y procesar un dataset de traducción del inglés al español. Abajo se deja igualmente la celda para descargar y cargar el dataset (se puede evaluar las veces que haga falta, ya que se descarga tan solo una vez, y se almacena en el directorio $HOME/.keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alarc\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import pathlib\n",
    "\n",
    "text_file = keras.utils.get_file(\n",
    "    fname=\"spa-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset viene en el siguiente formato: cada línea del fichero es una frase en inglés seguida por la correspondiente en español, separados por un tabulador. La siguiente celda separa cada frase en cada idioma, y además al español (idioma destino) le añade los tokens [start] y [end], necesarios para controlar la generación de la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "text_file = Path(text_file)\n",
    "\n",
    "with open(text_file, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "\n",
    "    text_pairs = []\n",
    "for line in lines:\n",
    "    eng, spa = line.split(\"\\t\")\n",
    "    spa = \"[start] \" + spa + \" [end]\"\n",
    "    text_pairs.append((eng, spa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"My driver's license expires at the end of this month.\", '[start] Mi licencia de conducir expira a final de este mes. [end]')\n",
      "(\"I'm dependable.\", '[start] Soy confiable. [end]')\n",
      "('She kept quiet.', '[start] Ella se quedó quieta. [end]')\n",
      "('Tom wanted to meet you.', '[start] Tom quería conocerle. [end]')\n",
      "('The glass shattered into pieces.', '[start] El vidrio se hizo trizas. [end]')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118964 total pairs\n",
      "83276 training pairs\n",
      "17844 validation pairs\n",
      "17844 test pairs\n"
     ]
    }
   ],
   "source": [
    "# Este código separa el conjunto de entrenamiento en train, val y test\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"I'm not sure I believe you.\", '[start] No estoy seguro de que te crea. [end]')\n"
     ]
    }
   ],
   "source": [
    "print(train_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelos tipo seq-to-seq con Teacher Forcing\n",
    "\n",
    "Un modelo de tipo sequence-to-sequence (seq-to-seq, o simplemente, seq2seq), se caracterizan porque reciben como entrada secuencias (texto) y generan como salida otra secuencia (texto). En nuestro caso la entrada será una frase en inglés y la salida será la frase en español.\n",
    "\n",
    "Estos modelos se caracterizan porque están divididos en dos partes: un *encoder* y un *decoder*. Estos dos modelos se componen de la siguiente forma para conformar el modelo seq2seq (también conocido como *teacher forcing*):\n",
    "\n",
    "![neural machine translation](img/seq2seq-teacher-forcing.png)\n",
    "\n",
    "\n",
    "* El **encoder**:\n",
    "  * **Recibe** la *secuencia de entrada* (frase en inglés). Cada token será una palabra, y se usará su representación con un word embedding pre-entrenado (Glove, Word2vec, FastText ...).\n",
    "  * **Devuelve** el *estado oculto* de la última neurona de la red recurrente, que sirve como continuación para el decoder. Si es una LSTM, será el último hidden state y el cell state.\n",
    "* El **decoder**:\n",
    "  * **Recibe**:\n",
    "    * El *último estado oculto (hidden state, cell state)* generado en el encoder.\n",
    "    * La *secuencia de salida*, incluyendo el [start]. \n",
    "  * **Devuelve** la secuencia de salida desplazada en 1 posición. Si la frase original es \"[start] Hablé con Tom [end]\", la salida será \"Hablé con Tom [end]\".\n",
    "  \n",
    "La configuración del decoder es así porque se empleará en tiempo de inferencia de forma *auto-regresiva*; es decir: empezamos con tan solo \"[start]\", y el decoder generará la siguiente palabra (por ejemplo, \"hablé\"); esta palabra se concatena a la solución parcial, teniendo \"[start] hablé\"; se repite el proceso, le damos al decoder esa solución parcial y dará la siguiente palabra (por ejemplo, \"con\"), y la añadimos a la solución parcial \"[start] hablé con\", y así hasta alcanzar el token [end]. \n",
    "  \n",
    "Recuerda que la salida del modelo indicará en formato one-hot cual es la siguiente palabra. Las entradas (del encoder y del decoder) serán las secuencias de los tokens en formato one-hot (que después pasarán por la correspondiente capa de embedding, siendo para el inglés un embedding pre-entrenado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Cabecera: nombre y apellidos. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alfonso Alarcón Tamayo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Dataset: descripción, carga y procesado. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto que vamos a trabajar es un conjunto de frases en ingles seguidas de su traducción de español,vamos a cargar los datos , tokemizarlos y ver la frecuencia de estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de hacer la vectorización vamos a comprobar el número de palabras medio de las frases llamando a lines (lines es una combinacion de la palabra en inglés seguida de la de español) así que el resultado debe ser aproximadamente la mitad\n",
    "\n",
    "\n",
    "En este caso podemos ver que el valor de las frases son unas 40 palabras por lo que cada frase tendra aproximadamente 20 palabras, así que vamos a definir la longitud máxima de las frases en 20, si es menor se hará padding para rellenar y si es mayor se recortará. Esto lo hago sobretodo por la falta de capacidad computacional y para no tardar demasiado tiempo en entrenar mi modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sequence = [len(seq) for seq in lines]\n",
    "\n",
    "# Mostramos los datos\n",
    "plt.hist(sequence, bins=30)\n",
    "plt.xlabel('Longitud de las frases(x2)')\n",
    "plt.ylabel('Frecuencia')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora toca vectorizar, para este apartado vamos a usar el mismo método que en el ejemplo 2 ya que hasta este punto es igual para nuestro trabajo\n",
    "\n",
    "En primer lugar se han definido los caracteres a eliminar, los corchetes y el caracter \"¿\" que se encuentra solo en el idioma español\n",
    "\n",
    "El método de custom_standardization sirve para pasar a minúsculas todos los elementos y reemplazar los caracteres de strip_chars (comas, signos de interrogación...)\n",
    "\n",
    "Después se ha definido el vocabulario máximo (que es el mismo que he definido para el word embedding ,10000 palabras), el tamaño de la secuencia , que he comentado anteriormente el porque de este valor y el batch_size que lo he reducido a 32 para usar lotes más pequeños\n",
    "\n",
    "Después hemos llamado a TextVectorizacion que es un método de keras que sirve para convertir secuencias de texto en secuencias de enteros\n",
    "\n",
    "\n",
    "Finalmente generamos listas para cada valor y con el método adapt la usamos para que las capas  \"aprenda\" del conjunto de textos proporcionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alarc\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alarc\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf_strings.lower(input_string)\n",
    "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
    "\n",
    "vocab_size = 10000\n",
    "sequence_length = 20\n",
    "batch_size = 32\n",
    "\n",
    "eng_vectorization = TextVectorization(max_tokens=vocab_size,output_mode=\"int\",output_sequence_length=sequence_length,)\n",
    "\n",
    "spa_vectorization = TextVectorization(max_tokens=vocab_size,output_mode=\"int\",output_sequence_length=sequence_length + 1,standardize=custom_standardization,)\n",
    "\n",
    "\n",
    "train_eng_texts = [pair[0] for pair in train_pairs]\n",
    "train_spa_texts = [pair[1] for pair in train_pairs]\n",
    "eng_vectorization.adapt(train_eng_texts)\n",
    "spa_vectorization.adapt(train_spa_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar que la vectorizacion se ha realizado correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto : I'm not sure I believe you.\n",
      "Tokens: [ 34  33 232   3 220   5   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Tomar la primera frase de train_eng_texts\n",
    "first_eng_text = train_eng_texts[0]\n",
    "\n",
    "# Vectorizamos la primera frase del conjunto\n",
    "vectorized_text_eng = eng_vectorization(tf.constant([first_eng_text]))\n",
    "\n",
    "# Mostramos el resultado obtenido\n",
    "print(f\"Texto : {first_eng_text}\")\n",
    "print(f\"Tokens: {vectorized_text_eng.numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto : [start] No estoy seguro de que te crea. [end]\n",
      "Tokens: [   2    7   37  208    4    5   28 6047    3    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Tomar la primera frase de train español\n",
    "first_spa_text = train_spa_texts[0]\n",
    "\n",
    "# la vectorizamos\n",
    "vectorized_text_spa = spa_vectorization(tf.constant([first_spa_text]))\n",
    "\n",
    "# Mostramos el resultado obtenido\n",
    "print(f\"Texto : {first_spa_text}\")\n",
    "print(f\"Tokens: {vectorized_text_spa.numpy()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Selección y carga del word embedding para el inglés. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui lo que vamos a hacer ahora es cargar ya un modelo preentrenado para aprovecharnos de este, más concretamente usaremos glove, para cargar estos datos tenemos que descargar y descomprimir los archivos (en mi caso) en la carpeta de este proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "glove_dir = 'glove.6B'\n",
    "\n",
    "# El archivo esta en el mismo directorio\n",
    "glove_path = 'glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos los vectores de glove y los incializamos, recorremos cada linea para obtener su palabra y su vector, y lo almacenamos en un diccionario embedding_index. Teniendo así por una parte la palabra y por otra como valores los coeficientes de esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_index = {}\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo que vamos a hacer es crear la matrix que le vamos a cargar a la capa de inmersion, el tamaño de esta será de Max_words que son 10000 en nuestro caso y el embedim_dim que es 100, el vocabulario será el que hemos obtenido en eng_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((10000, embedding_dim))\n",
    "\n",
    "for i, word in enumerate(eng_vectorization.get_vocabulary()):\n",
    "    if i < vocab_size:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al crear el modelo tenemos que pasarle una capa embedding con el aprendizaje , abajo he especificado como quedaría al añadirla  al modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Capa de embedding con GloVe\n",
    "glove_layer = Embedding(\n",
    "    input_dim=vocab_size,  # tamaño del vocabulario =10000\n",
    "    output_dim=embedding_dim,  # Dimensión del embedding = 100\n",
    "    weights=[embedding_matrix],  # Pesos de la matriz definido anteriormente\n",
    "    input_length=sequence_length,  # Longitud de la secuencias = 20\n",
    "    trainable=False  # No queremos que se actualicen los pesos\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Modelo y configuración creadas en Keras y su entrenamiento. Debe incluir una explicación razonada de los componentes, y de la selección de valores como el número de unidades en las redes recurrentes (LSTM/GRU), dimensión del embedding, etc. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear el modelo el caso más parecido es el del ejemplo 3 y también podemos ver el ejemplo 2, para ello vamos a tratar de adaptar el método para nuestros datos y para nuestro traductor inglés-español ya que en el ejemplo es del francés al inglés y no usa embedding mientrás que nosotros hemos definido una capa con los datos extraidos de glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten\n",
    "\n",
    "# FIX mirar ejemplo 2 y 3\n",
    "model = Sequential()\n",
    "\n",
    "# Capa de Embedding\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size,  # tamaño del vocabulario =10000\n",
    "    output_dim=embedding_dim,  # Dimensión del embedding = 100\n",
    "    weights=[embedding_matrix],  # Pesos de la matriz definido anteriormente\n",
    "    input_length=sequence_length,  # Longitud de la secuencias = 20\n",
    "    trainable=False  # No queremos que se actualicen los pesos\n",
    "))\n",
    "\n",
    "model.add(LSTM(50, return_sequences=True))  \n",
    "model.add(LSTM(50)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# La última capa deberíia tener el num_decoder_tokens\n",
    "model.add(Dense(1, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alarc\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 20, 100)           1000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 20, 50)            30200     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                1632      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1052065 (4.01 MB)\n",
      "Trainable params: 52065 (203.38 KB)\n",
      "Non-trainable params: 1000000 (3.81 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compilamos\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Mostramos el modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Análisis de resultados con comparativa respecto del trabajo original (ejemplo 2) basado en transformers (no es necesario mejorarlo). Si se hace la parte opcional (comparar con un modelo pre-entrenado de HuggingFace), indicar la comparativa. El análisis puede ser cualitativo, haciendo pruebas de texto. Se evaluará con 1 punto extra si se hace un análisis con métricas como BLEU y ROUGE (se pueden usar desde KerasNLP). </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Bibliografía utilizada (enlaces web, material de clase, libros, etc.). </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/examples/nlp/neural_machine_translation_with_transformer/\n",
    "    \n",
    "https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7\n",
    "\n",
    "https://keras.io/examples/nlp/lstm_seq2seq/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
