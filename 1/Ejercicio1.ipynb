{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkHEHL9WLDeu"
   },
   "source": [
    "# Ejercicio 1. Red Neuronal en Keras y ScikitLearn\n",
    "\n",
    "En este primer ejercicio tendrás que trabajar con **Keras** y **ScikitLearn** para construir una red neuronal artificial multicapa que se ajuste a los datos en el fichero CSV que se adjunta: *diabetes.csv*\n",
    "\n",
    "Este fichero contiene el diagnóstico de diabetes de los indios Pima. Basado en datos personales (edad, número de \n",
    "veces de embarazo) y los resultados de los reconocimientos médicos (por ejemplo, presión sanguínea, índice de masa corporal, resultado de la prueba de tolerancia a la glucosa, etc.), intenta decidir si un indio Pima tiene diabetes o no.\n",
    "\n",
    "![pima](img/pima.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ec_TFbA5LAs-"
   },
   "source": [
    "## 1. Enunciado\n",
    "\n",
    "Basándote en la Práctica 3.2 (Keras vs SKLearn), y usando el dataset adjunto (ver apartado 3), crea **al menos 4** redes neuronales con arquitecturas distintas usando Keras. Como mínimo deben diferir **siempre** en los siguientes aspectos:\n",
    "* Aspecto 1: El número de capas, nodos en ellas, y función de activación en las capas ocultas (pueden ser distintas según la capa).\n",
    "* Aspecto 2: Factor de aprendizaje, número de épocas, y/o función de pérdida\n",
    "* Aspecto 3: Método de optimización (SGD, Adam, RMSprop, Adagrad...).\n",
    "\n",
    "Por ejemplo, una red debe tener un número distinto de capas, número de épocas y método de optimización. Esta vez estamos en un problema de *clasificación binaria*, por lo que no tienes que convertir a one-hot la variable objetivo. Según lo visto en el módulo 2, ¿Qué tipo de capa de salida necesitamos? Puedes hacer uso de la [referencia de Keras](https://keras.io/api/).\n",
    "\n",
    "Particiona el conjunto de datos en subconjunto de entrenamiento y de test (indica el % que has usado para cada uno). Explica brevemente cada red diseñada y las razones de su configuración, así como los elementos empleados (es decir, explicar brevemente qué es ReLU si se utiliza, etc.) Analiza los resultados obtenidos para cada combinación. ¿Cuándo converge más?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrega\n",
    "\n",
    "La entrega de este ejercicio se realiza a través de la tarea creada para tal efecto en Enseñanza Virtual. Tienes que __entregar un notebook, y el HTML generado__ a partir de él, cuyas celdas estén ya evaluadas.\n",
    "\n",
    "La estructura del notebook debe contener los siguientes apartados:\n",
    "\n",
    "0. Cabecera: nombre y apellidos.\n",
    "1. Dataset: descripción y carga.\n",
    "2. Preparación de los datos para ser usados en tensorflow.\n",
    "3. Modelos creados en Keras (un sub-apartado para cada uno, explicando de forma razonada, con tus palabras y usando figuras, la arquitectura y su configuración, indicando además cómo los has implementado con tensorflow).\n",
    "4. Entrenamiento y evaluación de cada modelo creado (un sub-apartado para cada uno).\n",
    "5. Análisis de resultados.\n",
    "6. Bibliografía utilizada (enlaces web, material de clase, libros, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Nota importante\n",
    "-----\n",
    "**HONESTIDAD ACADÉMICA Y COPIAS: un trabajo práctico es un examen, por lo que\n",
    "debe realizarse de manera individual. La discusión y el intercambio de\n",
    "información de carácter general con los compañeros se permite (e incluso se\n",
    "recomienda), pero NO AL NIVEL DE CÓDIGO. Igualmente el remitir código de\n",
    "terceros, OBTENIDO A TRAVÉS DE LA RED o cualquier otro medio, se considerará\n",
    "plagio.** \n",
    "\n",
    "**Cualquier plagio o compartición de código que se detecte significará\n",
    "automáticamente la calificación de CERO EN LA ASIGNATURA para TODOS los\n",
    "alumnos involucrados. Por tanto a estos alumnos NO se les conservará, para\n",
    "futuras convocatorias, ninguna nota que hubiesen obtenido hasta el momento.\n",
    "SIN PERJUICIO DE OTRAS MEDIDAS DE CARÁCTER DISCIPLINARIO QUE SE PUDIERAN\n",
    "TOMAR.**\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. El Dataset\n",
    "\n",
    "El siguiente código cargará los datos del fichero CSV adjunto al completo en las variables `X`e `Y`. Deberás hacer una división para conjunto de test y de train, razonando debidamente por qué has elegido el tamaño de cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos los paquetes necesarios\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Lectura del dataset\n",
    "train = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = np.array(train.iloc[:,0:8]), np.array(train.iloc[:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alfonso Alarcón Tamayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: descripción y carga.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este primer ejercicio vamos a aprender a extraer,manejar e interpretar la información que se encuentra dentro del archivo \"diabetes.csv\"\n",
    "\n",
    "Este fichero contiene el diagnóstico de los indios Pima indicando según características si esa persona padece o no diabetes. Los datos que se han estudiado para determinar si una persona padece o no diabetes son: \n",
    "\n",
    "* veces que ha estado embarazada (times_pregnant)\n",
    "* concentracion de glucosa (glucose_concentration)\n",
    "* presion arterial (blood_pressure)\n",
    "* grosor de la piel (skin_thickness)\n",
    "* nivel de insulina (serum_insulin)\n",
    "* peso/masa corporal (body_mass)\n",
    "* antecedentes familiares relacionados con la diabetes (diabetes_pedigree)\n",
    "* edad (age)\n",
    "\n",
    "Todos las características estudiadas están presentadas como variables numéricas\n",
    "\n",
    "El dataset es para crear una red neuronal a partir de la información del .csv, el cual trae 768 indios con características o antecedentes familiares y una clasificación binaria de si esa persona sufre diabetes, con el fin de aprender  y crear la red neuronal que ayude a encontrar\n",
    "\n",
    "\n",
    "![pima](img/pima.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno en primer lugar voy a importar varios métodos y librerias que voy a necesitar en la carga y creación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alarc\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Keras\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.utils import to_categorical, normalize\n",
    "from keras.optimizers import SGD,Adam,RMSprop,Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la lectura de los datos vamos a cargar la información del documento .csv como hemos visto en las prácticas, en primer lugar usaremos el método read_csv de pandas para cargar la información del excel en una variable.\n",
    "\n",
    "Con el comando train.shape podemos ver la estructura que tiene train, el cual consta de 768 personaslas cuales tienen 10 características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 10)\n"
     ]
    }
   ],
   "source": [
    "# Lectura del dataset\n",
    "train = pd.read_csv(\"diabetes.csv\")\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver la estructura llamando directamente a train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>serum_insulin</th>\n",
       "      <th>body_mass</th>\n",
       "      <th>diabetes_pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>no_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536513</td>\n",
       "      <td>0.020922</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.269504</td>\n",
       "      <td>0.505216</td>\n",
       "      <td>0.075576</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341282</td>\n",
       "      <td>0.105892</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394933</td>\n",
       "      <td>0.077284</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.118203</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.139197</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.053192</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.108454</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.327498</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.205380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588674</td>\n",
       "      <td>0.091802</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.224586</td>\n",
       "      <td>0.561848</td>\n",
       "      <td>0.105038</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_concentration  blood_pressure  skin_thickness  \\\n",
       "0          0.176471                  0.605        0.426230            0.00   \n",
       "1          0.352941                  0.720        0.590164            0.27   \n",
       "2          0.117647                  0.875        0.721311            0.00   \n",
       "3          0.705882                  0.605        0.639344            0.17   \n",
       "4          0.117647                  0.535        0.606557            0.30   \n",
       "..              ...                    ...             ...             ...   \n",
       "763        0.117647                  0.280        0.459016            0.28   \n",
       "764        0.117647                  0.545        0.754098            0.00   \n",
       "765        0.176471                  0.450        0.639344            0.00   \n",
       "766        0.058824                  0.510        0.606557            0.00   \n",
       "767        0.352941                  0.515        0.590164            0.32   \n",
       "\n",
       "     serum_insulin  body_mass  diabetes_pedigree       age  diabetes  \\\n",
       "0         0.000000   0.536513           0.020922  0.066667         1   \n",
       "1         0.269504   0.505216           0.075576  0.316667         0   \n",
       "2         0.000000   0.341282           0.105892  0.016667         0   \n",
       "3         0.000000   0.394933           0.077284  0.683333         0   \n",
       "4         0.118203   0.500745           0.139197  0.033333         0   \n",
       "..             ...        ...                ...       ...       ...   \n",
       "763       0.053192   0.360656           0.108454  0.016667         0   \n",
       "764       0.000000   0.636364           0.327498  0.550000         0   \n",
       "765       0.000000   0.636364           0.205380  0.000000         0   \n",
       "766       0.000000   0.588674           0.091802  0.350000         1   \n",
       "767       0.224586   0.561848           0.105038  0.566667         0   \n",
       "\n",
       "     no_diabetes  \n",
       "0              0  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "..           ...  \n",
       "763            1  \n",
       "764            1  \n",
       "765            1  \n",
       "766            0  \n",
       "767            1  \n",
       "\n",
       "[768 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos para ser usados en tensorflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto en teoría los datos para utilizar los datos con keras y tensorflow, tenemos que hacer una serie de preparativos para que los datos nos proporcionen información de manera correcta:\n",
    "\n",
    "* Lo primero que tendríamos que tener en cuenta es que Keras no acepta cadenas de texto como etiquetas por lo que tendríamos que codificar las etiquetas si fuese necesario para que devolviesen un valor de forma numérica, en nuestro caso los datos devuelven un valor 1 o 0 si sufre o no diabetes por lo que en este caso no sería necesario, un ejemplo que tendríamos que cambiar las etiquetas es si nos devolviesen diabetes tipo 1 o tipo 2, en este caso tendríamos que transformarlo a forma binaria, siendo el caso que es un 1 y el resto 0.\n",
    "\n",
    "* En segundo lugar en keras es necesario *Normalizar* las variables de entrada,como hemos visto en la parte teórica las redes neuronales son sensibles a las escalas de las caracteristicas y bueno, como el gradiente tiene en cuenta los valores de entrada, unos valores que difieran mucho o muy grandes pueden provocar cambios bruscos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del conjunto no todas las caracteristicas nos sirven de la misma manera ya que las últimas dos hacen referencia a si la persona es diabetica o no, por lo que separaremos en dos conjuntos, los valores de las caractertisticas en dos conjuntos (X) y la clasificación si es diabética (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(train.iloc[:,0:8]), np.array(train.iloc[:,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente con train_test_split podemos crear los subconjuntos de entrenamiento y de prueba. Con train test podemos especificar como queremos hacer la distribución de las muestras entre los dos conjuntos, en este caso al disponer de 768 muestras considero que el conjunto es pequeño y la distribución deberia hacerse de un 75% para entrenamiento y 25% para prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Modelos creados en Keras (un sub-apartado para cada uno, explicando de forma razonada, con tus palabras y usando figuras, la arquitectura y su configuración, indicando además cómo los has implementado con tensorflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros que vamos a cambiar en nuestros modelos son:\n",
    "\n",
    "    Número de capas: Como su nombre indica representa el número de capas de la red neuronal\n",
    "    Nodos de las capas: Son las neuronas que tiene cada capa\n",
    "    \n",
    "    Factor de aprendizaje: Con este hiper parámetro controlamos el número de pasos que toma el optimizador desde el \n",
    "    Numero de épocas: Indica cuantas veces vamos a recorrer el conjunto durante el entrenamiento\n",
    "    Función de pérdida: Es la que mide la diferencia entre las predicciones del modelo y las salida real durante el entrenamiento. Para problemas de clasificación binaria, 'binary_crossentropy' es la más común pero como en el enunciado piden que para cada caso sea distinto probaremos con distintas\n",
    "    \n",
    "    Método de optimización: Es el algoritmo que calcula los pesos durante el entrenamiento\n",
    "    \n",
    "    \n",
    "    Para implementar tensorflow tenemos que definir el modelo, que será como hemos visto un conjunto de capas, esto se hace con un modelo secuencial (model = Sequential()), después tenemos que especificar la capa de entrada con el nº de características de entrada (8 en este ejemplo) y su respectiva función de activación. para cada capa debemos añadir la función y el número de neuronas.\n",
    "    La última capa será la de salida que en este ejemplo será de sigmoide ya que estamos en clasificación binaria.\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  <center> Modelo 1 </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aspecto 1: \n",
    "    * El número de capas, nodos en ellas : 2 capas una oculta (16 neuronas) y una de salida(1 neurona)\n",
    "    * función de activación en las capas ocultas: una sola capa softmax\n",
    "    \n",
    "* Aspecto 2: \n",
    "    * Factor de aprendizaje : 0.002\n",
    "    * número de épocas : 225\n",
    "    * función de pérdida : binary_crossentropy (buena para clasificación binaria)\n",
    "    \n",
    "* Aspecto 3: Método de optimización\n",
    "    * Adam: Mejora el rendimiento con parametros dispersos y se adapta bien cuando hay ruido. Adam  es un algoritmo de optimización que combina las ventajas de los algoritmos RMSprop y Momentum para mejorar el proceso de aprendizaje.\n",
    "\n",
    "* Softmax: aunque se suele usar en problemas multiclase de salida, devuelve las % de que pertenezca a la clase siendo la suma de todas las % de 1 (ej: 0,7 diabetes+0,3Nodiabetes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alarc\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                144       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161 (644.00 Byte)\n",
      "Trainable params: 161 (644.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "# Capa oculta\n",
    "model1.add(Dense(16, input_shape=(8,)))\n",
    "model1.add(Activation('softmax'))\n",
    "#Capa salida\n",
    "model1.add(Dense(1))\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer=Adam(learning_rate=0.002), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  <center> Modelo 2 </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aspecto 1: \n",
    "    * El número de capas, nodos en ellas : 3 capas, 2 ocultas (16,8 neuronas respectivamente) y una de salida(1 neurona)\n",
    "    * función de activación en las capas ocultas: las dos ocultas con tahn\n",
    "    \n",
    "* Aspecto 2: \n",
    "    * Factor de aprendizaje : 0.01\n",
    "    * número de épocas : 150\n",
    "    * función de pérdida : mean_squared_error\n",
    "    \n",
    "* Aspecto 3: Método de optimización\n",
    "    * SDG: es el Descenso de Gradiente Estocástico este en cada iteracion coje un ejemplo aleatorio lo que evita minimos locales pero hace muchos calculos redundantes\n",
    "   \n",
    "* tanh : esta función limita los valores en -1 y 1, asi que los valores muy altos/bajos se aproximarán a esos números respectivamente aunque si se satura afecta al gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 289 (1.13 KB)\n",
      "Trainable params: 289 (1.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "# Capa oculta\n",
    "model2.add(Dense(16, input_shape=(8,)))\n",
    "model2.add(Activation('tanh'))\n",
    "#capa oculta 2\n",
    "model2.add(Dense(8))\n",
    "model2.add(Activation('tanh'))\n",
    "#Capa salida\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "model2.compile(optimizer=SGD(learning_rate=0.01, momentum=0.9), loss='mean_squared_error', metrics=[\"accuracy\"])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  <center> Modelo 3 </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aspecto 1: \n",
    "    * El número de capas, nodos en ellas : 4 capas, 3 ocultas (64,32,16 neuronas respectivamente) y una de salida(1 neurona)\n",
    "    * función de activación en las capas ocultas: las tres con relu\n",
    "    \n",
    "* Aspecto 2: \n",
    "    * Factor de aprendizaje : 0.001\n",
    "    * número de épocas : 75\n",
    "    * función de pérdida : mean_absolute_error\n",
    "    \n",
    "* Aspecto 3: Método de optimización\n",
    "    * RMSprop:  Bueno para problemas que recibimos constantes datos, es bueno para problemas donde el gradiente varie\n",
    "    \n",
    "* relu : Da una salida igual a cero cuando la entrada es negativa, y una salida igual a la entrada cuando es positiva, no se satura y es muy eficiente pero matar neuronas(que no se activen más)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3201 (12.50 KB)\n",
      "Trainable params: 3201 (12.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(64, input_shape=(8,), activation='relu'))\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dense(16, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(optimizer=RMSprop(learning_rate=0.001,momentum=0.1), loss='mean_absolute_error', metrics=['accuracy'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  <center> Modelo 4 </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aspecto 1: \n",
    "    * El número de capas, nodos en ellas : 5 capas, 4 ocultas (128,64,32,16 neuronas) y una de salida(1 neurona)\n",
    "    * función de activación en las capas ocultas: Sigmoid\n",
    "    \n",
    "* Aspecto 2: \n",
    "    * Factor de aprendizaje : 0.0000000001\n",
    "    * número de épocas : 20\n",
    "    * función de pérdida : hinge\n",
    "    \n",
    "* Aspecto 3: Método de optimización\n",
    "    * Adagrad: este método calcula un learning rate  para cada parametro en función de los anteriores, a los atributos más dispersos les da un learning rate más alto\n",
    "    \n",
    "    \n",
    "* Sigmoid : Es la que se suele usar siempre para claisficación binaria, si se saturan las neuronas pueden matar el gradiente y es muy costoso computacionalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 128)               1152      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12033 (47.00 KB)\n",
      "Trainable params: 12033 (47.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(128,  input_shape=(8,), activation='sigmoid'))\n",
    "model4.add(Dense(64, activation='sigmoid'))\n",
    "model4.add(Dense(32, activation='sigmoid'))\n",
    "model4.add(Dense(16, activation='sigmoid'))\n",
    "model4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model4.compile(optimizer=Adagrad(learning_rate=0.0000000001), loss='hinge', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación de cada modelo creado (un sub-apartado para cada uno)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  <center> Modelo 1 </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alarc\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\alarc\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "model1.fit(train_X, train_y, epochs=225, batch_size=55, verbose=0)\n",
    "\n",
    "loss, accuracy = model1.evaluate(test_X, test_y, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  <center> Modelo 2 </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.81\n"
     ]
    }
   ],
   "source": [
    "model2.fit(train_X, train_y, epochs=150, batch_size=1, verbose=0)\n",
    "\n",
    "loss, accuracy = model2.evaluate(test_X, test_y, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  <center> Modelo 3 </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.66\n"
     ]
    }
   ],
   "source": [
    "model3.fit(train_X, train_y, epochs=75, batch_size=35, verbose=0)\n",
    "\n",
    "loss, accuracy = model3.evaluate(test_X, test_y, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  <center> Modelo 4 </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.34\n"
     ]
    }
   ],
   "source": [
    "model4.fit(train_X, train_y, epochs=20, batch_size=10, verbose=0)\n",
    "\n",
    "loss, accuracy = model4.evaluate(test_X, test_y, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número de epochs y batch influye en gran medida el coste computacional, ya que para entrenar un modelo con un batch_size de 1 mas variabilidad por lo que el modelo tarda mucho más tiempo en calcular el rendimiento.(cuanto mas pequeño más varía pero el coste es mayor), se puede ver en el modelo 2 que le paso un batch=1 y el modelo tarda mucho más que los otros.\n",
    "\n",
    "La elección del número de capas es otro aspecto crítico y su impacto depende en gran medida del problema, por ejemplo, aumentar el número de capas en una red neuronal puede aumentar su capacidad para aprender patrones complejos,pero también existe el riesgo de sobreajuste(el cual podremos combatir con dropout o la regularización l1 o l2)\n",
    "\n",
    "La función de activación influye en el rendimiento del modelo ya que dependiendo del tipo de ejercicio necesitaremos una u otra. En este caso necesitamos de salida una sigmoid ya que es un problema de clasificación binaria\n",
    "\n",
    "La tasa de aprendizaje y el nº de epocas están muy relacionadas, si la tasa es muy baja y el nº de epochs es muy pequeño puede provocar un rendimiento muy deficiente, ya que la convergencia es muy lenta y no le da tiempo\n",
    "\n",
    "El último caso es un rendimiento muy malo ya que he puesto un learning rate muy muy bajo, esto provoca que tarde mucho en converger, por lo que voy a necesitar muchas epochs, en este caso como he especificado pocas, el rendimiento es bastante malo como he comentado en el párrafo anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografía utilizada (enlaces web, material de clase, libros, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/miguelamda/DL/blob/master/3.%20Frameworks%20Software/Practica3.2.%20Keras%20versus%20SKLearn.ipynb#scrollTo=LLfjBX8gJRnU\n",
    "\n",
    "https://www.freecodecamp.org/news/how-to-pick-the-best-learning-rate-for-your-machine-learning-project-9c28865039a8/\n",
    "\n",
    "https://datascience.stackexchange.com/questions/26792/difference-between-rmsprop-with-momentum-and-adam-optimizers#:~:text=Adam%20is%20slower%20to%20change,both%20use%20the%20same%20learning_rate).\n",
    "\n",
    "https://www.sabrepc.com/blog/Deep-Learning-and-AI/Epochs-Batch-Size-Iterations"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "3 Maneras de Programar a una Red Neuronal.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
